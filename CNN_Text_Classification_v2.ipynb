{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafile = 'reviews_Books_5.json.gz'\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions for getting data from datafile\n",
    "import gzip\n",
    "def parse(path, topN=None):\n",
    "    with gzip.open(path, 'r') as g:\n",
    "        lc = 0\n",
    "        for l in g:\n",
    "            lc += 1\n",
    "            yield eval(l)\n",
    "            if topN != None and lc == topN: break\n",
    "                \n",
    "def extractWithFeedback(data, n, minTotalFeedbacks=10):\n",
    "    reviews_w_fb = []\n",
    "    for i in parse(data):\n",
    "        if len(i['reviewText']) < 10:\n",
    "            continue\n",
    "        if i['helpful'][1] > minTotalFeedbacks:\n",
    "            reviews_w_fb.append(i)\n",
    "        if len(reviews_w_fb) == n:\n",
    "            break\n",
    "    return reviews_w_fb\n",
    "\n",
    "def getData(data, totalSample, useCache=True, minTotalFeedbacks=10, split=[0.6,0.2,0.2]):\n",
    "    import pickle\n",
    "    import os\n",
    "    if useCache and os.path.isfile(\"train_data.p\") and os.path.isfile(\"dev_data.p\") and os.path.isfile(\"test_data.p\"):\n",
    "        print(\"using cached data\")\n",
    "        with open(\"train_data.p\", \"rb\") as f:\n",
    "            train_data = pickle.load(f)\n",
    "        with open(\"dev_data.p\", \"rb\") as f:\n",
    "            dev_data = pickle.load(f)\n",
    "        with open(\"test_data.p\", \"rb\") as f:\n",
    "            test_data = pickle.load(f)\n",
    "        return train_data, dev_data, test_data\n",
    "            \n",
    "    # probably not needed, but shuffle the data just to be safe\n",
    "    samples = np.random.permutation(extractWithFeedback(data, totalSample, minTotalFeedbacks))\n",
    "    split_idx1 = int(split[0]*len(samples))\n",
    "    split_idx2 = split_idx1+int(split[1]*len(samples))\n",
    "    train_data = samples[:split_idx1]\n",
    "    dev_data = samples[split_idx1:split_idx2]\n",
    "    test_data = samples[split_idx2:]\n",
    "    \n",
    "    with open(\"train_data.p\", \"wb\") as f:\n",
    "        pickle.dump(train_data, f)\n",
    "    with open(\"dev_data.p\", \"wb\") as f:\n",
    "        pickle.dump(dev_data, f)\n",
    "    with open(\"test_data.p\", \"wb\") as f:\n",
    "        pickle.dump(test_data, f)\n",
    "    \n",
    "    return train_data, dev_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached data\n"
     ]
    }
   ],
   "source": [
    "total_sample = 10000\n",
    "train_data, dev_data, test_data = getData(datafile, total_sample, useCache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asin': '000649885X',\n",
       " 'helpful': [6, 21],\n",
       " 'overall': 1.0,\n",
       " 'reviewText': \"After reading The Farseer Trilogy which was very promising, I decided to take another chance with the author and try The Ship of Magic series. This first book is very silly. The concept of a liveship which speaks to it's  occupants was intriguing but it loses it's appeal as the characters were  very annoying, and the magic was very unsophisticated. I tried very hard to  find some good in this novel but it falls short of anything spectacular.  Only for the extreemely imaginative and open minded. If you have your feet  planted firmly on the ground, this fantasy novel is not for you. Goodkind  fans will find this novel a hard read. The Farseer trilogy is far better.\",\n",
       " 'reviewTime': '05 6, 2000',\n",
       " 'reviewerID': 'A3SPHSI6Q9HO1G',\n",
       " 'reviewerName': 'Amazon Customer \"funnicky\"',\n",
       " 'summary': 'For the extremely imaginative only !',\n",
       " 'unixReviewTime': 957571200}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenize and preprocess text\n",
    "import utils; reload(utils)\n",
    "def preprocessAll():\n",
    "    for dataset in (train_data, test_data, dev_data):\n",
    "        for data in dataset:\n",
    "            raw_text = data['reviewText']\n",
    "            sentences = sent_tokenize(raw_text)\n",
    "            final_tokens = []\n",
    "            for s in sentences:\n",
    "                final_tokens.append('<s>')\n",
    "                for w in word_tokenize(s):\n",
    "                    final_tokens.append(utils.canonicalize_word(w))\n",
    "            final_tokens.append('</s>')\n",
    "            data['procTokens'] = final_tokens\n",
    "preprocessAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save processed text\n",
    "import pickle\n",
    "with open('train_data_proc.p', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "with open('dev_data_proc.p', 'wb') as f:\n",
    "    pickle.dump(dev_data, f)\n",
    "with open('test_data_proc.p', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "import pickle\n",
    "with open('train_data_proc.p', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('dev_data_proc.p', 'rb') as f:\n",
    "    dev_data = pickle.load(f)\n",
    "with open('test_data_proc.p', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    \"\"\"Flatten a list-of-lists into a single list.\"\"\"\n",
    "    return list(itertools.chain.from_iterable(list_of_lists))\n",
    "\n",
    "class vocabulary:\n",
    "    START_TOKEN = \"<s>\"\n",
    "    END_TOKEN = \"</s>\"\n",
    "    UNK_TOKEN = \"<unk>\"\n",
    "    \n",
    "    def __init__(self, train_data, test_data, dev_data, size):\n",
    "        self.unigram_counts = collections.Counter(flatten([t['procTokens'] for t in train_data])\n",
    "                                                  +flatten([t['procTokens'] for t in test_data])\n",
    "                                                  +flatten([t['procTokens'] for t in dev_data]))\n",
    "        top_counts = self.unigram_counts.most_common(None if size is None else (size - 1))\n",
    "        vocab = ([self.UNK_TOKEN] + [w for w,c in top_counts])\n",
    "        # Assign an id to each word, by frequency\n",
    "        self.id_to_word = dict(enumerate(vocab))\n",
    "        self.word_to_id = {v:k for k,v in self.id_to_word.iteritems()}\n",
    "        self.size = len(self.id_to_word)\n",
    "        if size is not None:\n",
    "            assert(self.size <= size)\n",
    "\n",
    "        # Store special IDs\n",
    "        self.START_ID = self.word_to_id[self.START_TOKEN]\n",
    "        self.END_ID = self.word_to_id[self.END_TOKEN]\n",
    "        self.UNK_ID = self.word_to_id[self.UNK_TOKEN]\n",
    "\n",
    "    def words_to_ids(self, words):\n",
    "        return [self.word_to_id.get(w, self.UNK_ID) for w in words]\n",
    "\n",
    "    def ids_to_words(self, ids):\n",
    "        return [self.id_to_word[i] for i in ids]\n",
    "\n",
    "    def sentence_to_ids(self, words):\n",
    "        return [self.START_ID] + self.words_to_ids(words) + [self.END_ID]\n",
    "\n",
    "    def ordered_words(self):\n",
    "        \"\"\"Return a list of words, ordered by id.\"\"\"\n",
    "        return self.ids_to_words(range(self.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = 10000\n",
    "vocab = vocabulary(train_data, test_data, dev_data, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate batch, and pad to same length\n",
    "def batchGenerator(dataset, batch_size, vocab, success_ratio=0.8, maxlength=None):\n",
    "    for i in xrange(0, len(dataset), batch_size):\n",
    "        batch_data = dataset[i:i+batch_size]\n",
    "        if maxlength == None: \n",
    "            maxlength = max([len(d['procTokens']) for d in batch_data])\n",
    "        x = []\n",
    "        y = []\n",
    "        raw = []\n",
    "        for data in batch_data:\n",
    "            tokens = data['procTokens']\n",
    "            if len(tokens) > maxlength:\n",
    "                tokens = tokens[:maxlength]\n",
    "            elif len(tokens) < maxlength:\n",
    "                tokens = tokens + ['</s>']*(maxlength-len(tokens))\n",
    "            x.append(vocab.words_to_ids(tokens))\n",
    "            helpful_ratio = data[\"helpful\"][0]*1.0/data[\"helpful\"][1]\n",
    "            raw.append(data[\"helpful\"])\n",
    "            if helpful_ratio > success_ratio:\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "        yield (x, y, raw)\n",
    "        \n",
    "# run like this\n",
    "#result = batchGenerator(test_data, 5, vocab, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '(', 'i', 'am', 'reviewing', 'the', 'DGDGDGDG', '<unk>', 'large', 'print', 'version', 'of', 'the', 'original', 'DGDGDGDG', 'book', 'by', '<unk>', '.', '<s>', 'illustrations', 'are', 'by', '<unk>', '<unk>', '.', '<s>', ')', 'this', 'fanciful', 'book', \"'s\", 'old-fashioned', 'style', 'and', 'content', 'almost', 'feels', 'as', 'if', 'it', 'were', 'written', 'at', 'the', 'turn', 'of', 'the', '19th', 'century', ',', 'and', 'the', 'james', \"'\", 'initial', 'misery', 'recalls', 'dickens', '.', '<s>', 'the', 'writing', \"'s\", 'rough', 'edges', 'make', 'it', 'seem', 'more', 'like', 'a', 'personal', 'story', ',', 'rather', 'than', 'the', 'product', 'of', 'some', 'anonymous', '<unk>', ',', 'the', 'beginning', 'of', 'the', 'book', '(', 'where', 'james', 'magically', 'escapes', 'from', 'his', '<unk>', ')', 'seems', 'contrived', ',', 'the', '<unk>', 'are', 'unbelievably', 'cruel', ',', 'and', 'the', 'writing', 'is', 'somehow', 'flat', '.', '<s>', 'however', ',', 'the', 'book', 'picks', 'up', 'after', 'james', 'and', 'his', '<unk>', 'insect', 'friends', 'escape', 'via', 'a', 'magic', 'peach', '.', '<s>', 'the', '<unk>', 'and', 'arguing', 'insect', 'personalities', 'are', 'reminiscent', 'of', 'those', 'in', '``', '<unk>', 'the', '<unk>', \"''\", 'and', '``', 'the', 'wizard', 'of', 'oz', '.', \"''\", '<s>', '(', 'the', '<unk>', '<unk>', 'and', 'worm', 'are', 'a', 'bit', 'like', 'emotionally', '<unk>', '<unk>', 'and', 'pessimistic', '<unk>', ';', 'the', '``', '<unk>', \"''\", 'plays', 'a', 'role', 'similar', 'to', 'the', '<unk>', '.', ')', '<s>', 'the', 'insects', \"'\", '<unk>', 'and', 'fear', 'is', 'balanced', 'by', 'james', \"'\", '<unk>', 'and', '<unk>', 'actions', 'that', 'save', 'them', 'from', 'sharks', ',', 'the', 'angry', '``', 'cloud', 'people', \"''\", '(', 'who', 'throw', '<unk>', ',', 'water', ',', 'and', '<unk>', 'paint', 'at', 'them', ')', ',', 'and', 'the', 'fearful', 'citizens', 'of', 'new', 'york', '<unk>', 'has', 'lots', 'of', 'word', 'play', '(', '``', 'oh', ',', 'just', 'look', 'at', 'the', '<unk>', 'gruesome', 'face', '!', '<s>', '``', ')', ',', 'and', 'songs', 'done', 'in', 'a', 'kind', 'of', '``', 'alice', 'of', '<unk>', \"''\", 'meets', '<unk>', 'style', ':', '``', 'i', \"'ve\", 'eaten', 'many', 'strange', 'and', '<unk>', 'dishes', 'in', 'my', 'time', ',', 'like', '<unk>', '<unk>', 'and', '<unk>', 'and', '<unk>', 'cooked', 'in', '<unk>', ',', 'and', 'mice', 'with', '<unk>', \"'re\", 'really', '<unk>', '<unk>', 'in', 'their', 'prime', '.', '<s>', '(', 'but', 'do', \"n't\", 'forget', 'to', '<unk>', 'them', 'with', 'just', 'a', '<unk>', 'of', '<unk>', '.', ')', \"''\", '<s>', 'as', 'you', 'can', 'see', ',', 'the', 'humor', '(', 'and', 'some', 'of', '<unk>', '<unk>', \"'s\", 'illustrations', 'for', 'the', 'DGDGDGDG', 'edition', ')', 'is', 'sometimes', '<unk>', ',', 'and', 'the', 'demise', 'of', 'the', '<unk>', 'is', 'not', 'like', 'that', 'pictured', 'in', 'the', 'movie', 'based', 'on', 'the', 'book', '(', 'they', 'get', 'run', 'over', 'by', 'the', 'peach', '.', ')', '<s>', 'overall', ',', 'however', ',', 'and', 'despite', 'its', 'slow', 'beginning', ',', 'the', 'book', 'is', '<unk>', 'and']\n"
     ]
    }
   ],
   "source": [
    "for r in batchGenerator(test_data[0:1], 1, vocab, 0.8, 400):\n",
    "    print(vocab.ids_to_words(r[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "def score_batch(pred_probs, targets):\n",
    "    pred = [1 if p>0.5 else 0 for p in pred_probs]\n",
    "    accuracy = metrics.accuracy_score(targets, pred)\n",
    "    precision = metrics.precision_score(targets, pred)\n",
    "    recall = metrics.recall_score(targets, pred)\n",
    "    f1 = metrics.f1_score(targets, pred)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Params:\n",
    "trained_filename = 'tf_saved/final_project_rnn_classifier_v2'\n",
    "\n",
    "max_length = 500\n",
    "num_classes = 1\n",
    "vocab_size = len(vocab.word_to_id)\n",
    "embedding_size = 200\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 128\n",
    "learning_rate = 0.01\n",
    "keep_prob = 0.8\n",
    "\n",
    "model_params = dict(sequence_length=max_length, num_classes=num_classes, vocab_size=vocab_size,\n",
    "      embedding_size=embedding_size, filter_sizes=filter_sizes, num_filters=num_filters, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LanguageModel(object):\n",
    "\n",
    "    def __init__(self, sequence_length, num_classes, vocab_size,\n",
    "      embedding_size, filter_sizes, num_filters, learning_rate, l2_reg_lambda =0.0):\n",
    "        \n",
    "        l2_loss = tf.constant(0.0)\n",
    "        \n",
    "        with tf.name_scope(\"Training_Parameters\"):\n",
    "            self.learning_rate_ = tf.constant(learning_rate, name=\"learning_rate\")\n",
    "            self.dropout_keep_prob = tf.constant(1.0, name=\"dropout_keep_prob\")\n",
    "\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        if num_classes == 1:\n",
    "            self.input_y = tf.placeholder(tf.float32, [None], name=\"input_y\")\n",
    "        else:\n",
    "            self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        \n",
    "        with tf.name_scope(\"embedding\"):\n",
    "            W = tf.Variable(\n",
    "                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "            \n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(\n",
    "                    self.embedded_chars_expanded,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "                # Apply nonlinearity\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                # Max-pooling over the outputs\n",
    "                pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(3, pooled_outputs)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "        \n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "        \n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.Variable(tf.truncated_normal([num_filters_total, num_classes], stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            self.logits_ = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"logits\")\n",
    "            self.pred_proba_ = tf.sigmoid(self.logits_, name=\"pred_proba\")\n",
    "            \n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            \n",
    "        with tf.name_scope(\"loss_function\"):\n",
    "            self.point_loss_ = tf.nn.sigmoid_cross_entropy_with_logits(tf.squeeze(self.logits_), self.input_y)\n",
    "            self.loss_ = tf.reduce_mean(self.point_loss_) + l2_reg_lambda * l2_loss\n",
    "            \n",
    "        with tf.name_scope(\"train_ops\"):\n",
    "            #tvars = tf.trainable_variables()\n",
    "            #grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss_, tvars),self.max_grad_norm_)\n",
    "            #optimizer = tf.train.GradientDescentOptimizer(self.learning_rate_)\n",
    "            #self.train_step_ = optimizer.apply_gradients(zip(grads, tvars))\n",
    "            #optimizer = tf.train.GradientDescentOptimizer(self.learning_rate_)\n",
    "            optimizer = tf.train.AdamOptimizer(self.learning_rate_)\n",
    "            self.train_step_ = optimizer.minimize(self.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to dump out some intermediate data\n",
    "def dumpIntermediateOutputs(inputBatch):\n",
    "    def _flatten(sentences):\n",
    "        final_sent = []\n",
    "        for sent in sentences:\n",
    "            final_sent.append(\"<s>\")\n",
    "            for word in sent:\n",
    "                final_sent.append(word)\n",
    "        final_sent.append(\"</s>\")\n",
    "        return final_sent\n",
    "    \n",
    "    w = []\n",
    "    for inputs in inputBatch:\n",
    "        padded_ids = vocab.words_to_ids(inputs)\n",
    "        w.append(padded_ids)\n",
    "    \n",
    "    with tf.Graph().as_default(), tf.Session() as session:\n",
    "        with tf.variable_scope(\"model\", reuse=None):\n",
    "            lm = LanguageModel(sequence_length=len(w[0]), num_classes=num_classes, vocab_size=vocab_size,\n",
    "      embedding_size=embedding_size, filter_sizes=filter_sizes, num_filters=num_filters, learning_rate=learning_rate)\n",
    "        \n",
    "        session.run(tf.initialize_all_variables())\n",
    "\n",
    "        feed_dict = { lm.input_x:w,\n",
    "               lm.dropout_keep_prob: 1.0,\n",
    "               lm.input_y: [1]*len(w)}\n",
    "                \n",
    "        pred, logits_ = session.run([lm.pred_proba_, lm.logits_], feed_dict)\n",
    "        return pred, logits_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00996649],\n",
       "        [ 0.00659992]], dtype=float32), array([[-4.59851027],\n",
       "        [-5.01407528]], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumpIntermediateOutputs([\"this is a test text , do some thing\".split(), \"this is another test text , do more thing\".split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set baseline\n",
      "{'f1': 0.65891819400983453, 'recall': 1.0, 'precision': 0.49133333333333334, 'accuracy': 0.49133333333333334}\n",
      "dev set baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.53649999999999998}\n",
      "test set baseline\n",
      "{'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.53049999999999997}\n"
     ]
    }
   ],
   "source": [
    "# baseline score - no training\n",
    "def baselineScore(dataset):\n",
    "    # test 2 batches on the first 10 training set\n",
    "    bi = batchGenerator(dataset, 100, vocab, 0.8, max_length)\n",
    "    \n",
    "    with tf.Graph().as_default(), tf.Session() as session:\n",
    "        with tf.variable_scope(\"model\", reuse=None):\n",
    "            lm = LanguageModel(**model_params)\n",
    "        \n",
    "        session.run(tf.initialize_all_variables())\n",
    "        \n",
    "        pred_prob = []\n",
    "        targets = []\n",
    "        for i,(w,y, raw) in enumerate(bi):\n",
    "            #print(\"batch #%s\"%i)\n",
    "            feed_dict = { lm.input_x:w,\n",
    "               lm.dropout_keep_prob: 1.0,\n",
    "               lm.input_y: [1]*len(w)}\n",
    "            pred_prob.extend(session.run(lm.pred_proba_, feed_dict))\n",
    "            targets.extend(y)\n",
    "        print(score_batch(pred_prob, targets))\n",
    "print(\"train set baseline\")\n",
    "baselineScore(train_data)\n",
    "print(\"dev set baseline\")\n",
    "baselineScore(dev_data)\n",
    "print(\"test set baseline\")\n",
    "baselineScore(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getScore(session, dataset, lm):\n",
    "    bi = batchGenerator(dataset, 100, vocab, 0.8, max_length)\n",
    "    pred_prob = []\n",
    "    targets = []\n",
    "    for i,(w,y, raw) in enumerate(bi):\n",
    "        feed_dict = { lm.input_x:w,\n",
    "           lm.dropout_keep_prob: 1.0,\n",
    "           lm.input_y: [1]*len(w)}\n",
    "        pred_prob.extend(session.run(lm.pred_proba_, feed_dict))\n",
    "        targets.extend(y)\n",
    "    print(score_batch(pred_prob, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator, train=False,\n",
    "              verbose=False, tick_s=10, \n",
    "              keep_prob=0.8, learning_rate=0.01):\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time\n",
    "    total_cost = 0.0\n",
    "    total_texts = 0\n",
    "    \n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        keep_prob = keep_prob\n",
    "        loss = lm.loss_\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        keep_prob = 1.0\n",
    "        loss = lm.loss_\n",
    "        \n",
    "    for i, (w, y, _) in enumerate(batch_iterator):\n",
    "        feed_dict = {\n",
    "            lm.learning_rate_: learning_rate,\n",
    "            lm.dropout_keep_prob: keep_prob,\n",
    "            lm.input_x: w,\n",
    "            lm.input_y: y\n",
    "        }\n",
    "\n",
    "        _, loss_val = session.run([train_op, loss], feed_dict)\n",
    "        \n",
    "        total_cost += loss_val\n",
    "        total_texts += len(w)\n",
    "        \n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_texts\n",
    "            avg_tps = total_texts / (time.time() - start_time)\n",
    "            print \"[batch %d]: seen %d texts at %d wps, loss = %.3f\" % (i,total_texts, avg_tps, avg_cost)\n",
    "            tick_time = time.time()\n",
    "    #return total_cost / total_texts\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "Training: total loss: 249.434\n",
      "[epoch 1] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.85324470876333736, 'recall': 0.82734056987788329, 'precision': 0.88082340195016251, 'accuracy': 0.86016666666666663}\n",
      "dev score\n",
      "{'f1': 0.64444444444444449, 'recall': 0.62567421790722766, 'precision': 0.66437571592210765, 'accuracy': 0.68000000000000005}\n",
      "[epoch 2] Starting epoch 2\n",
      "Training: total loss: 105.816\n",
      "[epoch 2] Completed in 0:01:47\n",
      "train score\n",
      "{'f1': 0.92964400202463304, 'recall': 0.93453188602442339, 'precision': 0.92480698220879487, 'accuracy': 0.93049999999999999}\n",
      "dev score\n",
      "{'f1': 0.6933888599687662, 'recall': 0.71844660194174759, 'precision': 0.67002012072434602, 'accuracy': 0.70550000000000002}\n",
      "[epoch 3] Starting epoch 3\n",
      "Training: total loss: 86.443\n",
      "[epoch 3] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.87171881951653574, 'recall': 0.99694708276797828, 'precision': 0.77444005270092231, 'accuracy': 0.85583333333333333}\n",
      "dev score\n",
      "{'f1': 0.70578778135048237, 'recall': 0.94714131607335494, 'precision': 0.56245996156310063, 'accuracy': 0.63400000000000001}\n",
      "[epoch 4] Starting epoch 4\n",
      "Training: total loss: 42.446\n",
      "[epoch 4] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.58913615697535293, 'recall': 0.41757123473541385, 'precision': 1.0, 'accuracy': 0.71383333333333332}\n",
      "dev score\n",
      "{'f1': 0.066184074457083755, 'recall': 0.034519956850053934, 'precision': 0.80000000000000004, 'accuracy': 0.54849999999999999}\n",
      "[epoch 5] Starting epoch 5\n",
      "Training: total loss: 24.314\n",
      "[epoch 5] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.99779324393142077, 'recall': 0.99694708276797828, 'precision': 0.99864084267753994, 'accuracy': 0.99783333333333335}\n",
      "dev score\n",
      "{'f1': 0.66703478741027056, 'recall': 0.65156418554476803, 'precision': 0.68325791855203621, 'accuracy': 0.69850000000000001}\n",
      "[epoch 6] Starting epoch 6\n",
      "Training: total loss: 8.593\n",
      "[epoch 6] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.97648227890029815, 'recall': 1.0, 'precision': 0.95404530744336569, 'accuracy': 0.97633333333333339}\n",
      "dev score\n",
      "{'f1': 0.69464428457234206, 'recall': 0.93743257820927728, 'precision': 0.55174603174603176, 'accuracy': 0.61799999999999999}\n",
      "[epoch 7] Starting epoch 7\n",
      "Training: total loss: 4.467\n",
      "[epoch 7] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.99460188933873139, 'recall': 1.0, 'precision': 0.98926174496644292, 'accuracy': 0.9946666666666667}\n",
      "dev score\n",
      "{'f1': 0.706984667802385, 'recall': 0.89536138079827399, 'precision': 0.58409570724841664, 'accuracy': 0.65600000000000003}\n",
      "[epoch 8] Starting epoch 8\n",
      "Training: total loss: 1.888\n",
      "[epoch 8] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 1.0, 'recall': 1.0, 'precision': 1.0, 'accuracy': 1.0}\n",
      "dev score\n",
      "{'f1': 0.6887417218543046, 'recall': 0.72923408845738946, 'precision': 0.65250965250965254, 'accuracy': 0.69450000000000001}\n",
      "[epoch 9] Starting epoch 9\n",
      "Training: total loss: 0.699\n",
      "[epoch 9] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 1.0, 'recall': 1.0, 'precision': 1.0, 'accuracy': 1.0}\n",
      "dev score\n",
      "{'f1': 0.70255474452554745, 'recall': 0.83063646170442285, 'precision': 0.60869565217391308, 'accuracy': 0.67400000000000004}\n",
      "[epoch 10] Starting epoch 10\n",
      "Training: total loss: 0.386\n",
      "[epoch 10] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 1.0, 'recall': 1.0, 'precision': 1.0, 'accuracy': 1.0}\n",
      "dev score\n",
      "{'f1': 0.69930069930069927, 'recall': 0.75512405609492983, 'precision': 0.65116279069767447, 'accuracy': 0.69899999999999995}\n"
     ]
    }
   ],
   "source": [
    "# run training\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "import time\n",
    "import utils; reload(utils)\n",
    "def runTraining(print_interval=5):\n",
    "    with tf.Graph().as_default(), tf.Session() as session:\n",
    "        tf.set_random_seed(42)\n",
    "        with tf.variable_scope(\"model\", reuse=None):\n",
    "            lm = LanguageModel(**model_params)\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        for epoch in xrange(1,num_epochs+1):\n",
    "            t0_epoch = time.time()\n",
    "            bi = batchGenerator(train_data, batch_size, vocab, 0.8, max_length)\n",
    "            print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "            cost = run_epoch(lm, session, bi, train=True, keep_prob=keep_prob, learning_rate=learning_rate)\n",
    "            print \"%s: total loss: %.03f\" % (\"Training\", cost)\n",
    "            print \"[epoch %d] Completed in %s\" % (epoch, utils.pretty_timedelta(since=t0_epoch))\n",
    "            \n",
    "            print(\"train score\")\n",
    "            getScore(session, train_data, lm)\n",
    "                \n",
    "            print(\"dev score\")\n",
    "            getScore(session, dev_data, lm)\n",
    "        # Save final model\n",
    "        saver.save(session, trained_filename)\n",
    "runTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "Training: total loss: 136.856\n",
      "[epoch 1] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.79395277730592839, 'recall': 0.79274084124830391, 'precision': 0.79516842463422932, 'accuracy': 0.79783333333333328}\n",
      "dev score\n",
      "{'f1': 0.61497610196494956, 'recall': 0.62459546925566345, 'precision': 0.60564853556485354, 'accuracy': 0.63749999999999996}\n",
      "[epoch 2] Starting epoch 2\n",
      "Training: total loss: 97.712\n",
      "[epoch 2] Completed in 0:01:49\n",
      "train score\n",
      "{'f1': 0.89619834710743806, 'recall': 0.91960651289009498, 'precision': 0.87395228884590592, 'accuracy': 0.89533333333333331}\n",
      "dev score\n",
      "{'f1': 0.65907966353290437, 'recall': 0.71844660194174759, 'precision': 0.60877513711151732, 'accuracy': 0.65549999999999997}\n",
      "[epoch 3] Starting epoch 3\n",
      "Training: total loss: 74.622\n",
      "[epoch 3] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.93996867931094485, 'recall': 0.91621438263229305, 'precision': 0.96498749553411933, 'accuracy': 0.9425}\n",
      "dev score\n",
      "{'f1': 0.64810690423162576, 'recall': 0.62783171521035597, 'precision': 0.66973532796317603, 'accuracy': 0.68400000000000005}\n",
      "[epoch 4] Starting epoch 4\n",
      "Training: total loss: 59.186\n",
      "[epoch 4] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.96975874957526331, 'recall': 0.96811397557666212, 'precision': 0.97140912185159978, 'accuracy': 0.97033333333333338}\n",
      "dev score\n",
      "{'f1': 0.67011910926980833, 'recall': 0.69795037756202805, 'precision': 0.64442231075697209, 'accuracy': 0.68149999999999999}\n",
      "[epoch 5] Starting epoch 5\n",
      "Training: total loss: 49.063\n",
      "[epoch 5] Completed in 0:01:51\n",
      "train score\n",
      "{'f1': 0.97914152732287529, 'recall': 0.96336499321573943, 'precision': 0.99544339291973361, 'accuracy': 0.97983333333333333}\n",
      "dev score\n",
      "{'f1': 0.65219874357509988, 'recall': 0.61596548004314999, 'precision': 0.69296116504854366, 'accuracy': 0.69550000000000001}\n",
      "[epoch 6] Starting epoch 6\n",
      "Training: total loss: 42.182\n",
      "[epoch 6] Completed in 0:01:49\n",
      "train score\n",
      "{'f1': 0.98962055470478127, 'recall': 0.98643147896879235, 'precision': 0.99283031751451012, 'accuracy': 0.98983333333333334}\n",
      "dev score\n",
      "{'f1': 0.6879834966477566, 'recall': 0.7195253505933118, 'precision': 0.65909090909090906, 'accuracy': 0.69750000000000001}\n",
      "[epoch 7] Starting epoch 7\n",
      "Training: total loss: 34.857\n",
      "[epoch 7] Completed in 0:01:48\n",
      "train score\n",
      "{'f1': 0.99387963277796665, 'recall': 0.99151967435549526, 'precision': 0.99625085207907293, 'accuracy': 0.99399999999999999}\n",
      "dev score\n",
      "{'f1': 0.68947641264904092, 'recall': 0.71736785329018338, 'precision': 0.66367265469061876, 'accuracy': 0.70050000000000001}\n",
      "[epoch 8] Starting epoch 8\n",
      "Training: total loss: 31.174\n",
      "[epoch 8] Completed in 0:01:47\n",
      "train score\n",
      "{'f1': 0.99443413729128027, 'recall': 1.0, 'precision': 0.98892988929889303, 'accuracy': 0.99450000000000005}\n",
      "dev score\n",
      "{'f1': 0.71048951048951048, 'recall': 0.82200647249190939, 'precision': 0.62561576354679804, 'accuracy': 0.6895}\n",
      "[epoch 9] Starting epoch 9\n",
      "Training: total loss: 26.943\n",
      "[epoch 9] Completed in 0:01:47\n",
      "train score\n",
      "{'f1': 0.99762308998302207, 'recall': 0.99660786974219806, 'precision': 0.99864038069340588, 'accuracy': 0.9976666666666667}\n",
      "dev score\n",
      "{'f1': 0.68868435300487263, 'recall': 0.68608414239482196, 'precision': 0.69130434782608696, 'accuracy': 0.71250000000000002}\n",
      "[epoch 10] Starting epoch 10\n",
      "Training: total loss: 24.938\n",
      "[epoch 10] Completed in 0:01:47\n",
      "train score\n",
      "{'f1': 0.99695637470409193, 'recall': 1.0, 'precision': 0.99393122049898852, 'accuracy': 0.997}\n",
      "dev score\n",
      "{'f1': 0.71167369901547117, 'recall': 0.81877022653721687, 'precision': 0.62935323383084574, 'accuracy': 0.6925}\n"
     ]
    }
   ],
   "source": [
    "# smaller learning rate, and with L2 reg\n",
    "import time\n",
    "import utils; reload(utils)\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "max_length = 500\n",
    "num_classes = 1\n",
    "vocab_size = len(vocab.word_to_id)\n",
    "embedding_size = 200\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 128\n",
    "keep_prob = 0.8\n",
    "l2_reg_lambda = 0.5\n",
    "\n",
    "trained_filename = 'tf_saved/final_project_rnn_classifier_v2_2'\n",
    "\n",
    "model_params = dict(sequence_length=max_length, num_classes=num_classes, vocab_size=vocab_size,\n",
    "      embedding_size=embedding_size, filter_sizes=filter_sizes, num_filters=num_filters, \n",
    "      learning_rate=learning_rate, l2_reg_lambda=l2_reg_lambda)\n",
    "\n",
    "def runTraining(print_interval=5):\n",
    "    with tf.Graph().as_default(), tf.Session() as session:\n",
    "        tf.set_random_seed(42)\n",
    "        with tf.variable_scope(\"model\", reuse=None):\n",
    "            lm = LanguageModel(**model_params)\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        for epoch in xrange(1,num_epochs+1):\n",
    "            t0_epoch = time.time()\n",
    "            bi = batchGenerator(train_data, batch_size, vocab, 0.8, max_length)\n",
    "            print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "            cost = run_epoch(lm, session, bi, train=True, keep_prob=keep_prob, learning_rate=learning_rate)\n",
    "            print \"%s: total loss: %.03f\" % (\"Training\", cost)\n",
    "            print \"[epoch %d] Completed in %s\" % (epoch, utils.pretty_timedelta(since=t0_epoch))\n",
    "            \n",
    "            print(\"train score\")\n",
    "            getScore(session, train_data, lm)\n",
    "                \n",
    "            print(\"dev score\")\n",
    "            getScore(session, dev_data, lm)\n",
    "        # Save final model\n",
    "        saver.save(session, trained_filename)\n",
    "\n",
    "runTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "Training: total loss: 143.671\n",
      "[epoch 1] Completed in 0:01:47\n",
      "train score\n",
      "{'f1': 0.76094552929085302, 'recall': 0.62788331071913162, 'precision': 0.96557120500782467, 'accuracy': 0.8061666666666667}\n",
      "dev score\n",
      "{'f1': 0.45041014168530952, 'recall': 0.32578209277238401, 'precision': 0.72946859903381644, 'accuracy': 0.63149999999999995}\n",
      "[epoch 2] Starting epoch 2\n",
      "Training: total loss: 78.309\n",
      "[epoch 2] Completed in 0:01:46\n",
      "train score\n",
      "{'f1': 0.91467042429935796, 'recall': 0.99084124830393483, 'precision': 0.84937481826112238, 'accuracy': 0.90916666666666668}\n",
      "dev score\n",
      "{'f1': 0.70432178005990598, 'recall': 0.88781014023732474, 'precision': 0.58368794326241136, 'accuracy': 0.65449999999999997}\n",
      "[epoch 3] Starting epoch 3\n",
      "Training: total loss: 49.810\n",
      "[epoch 3] Completed in 0:01:46\n",
      "train score\n",
      "{'f1': 0.97651006711409405, 'recall': 0.98710990502035278, 'precision': 0.96613545816733071, 'accuracy': 0.97666666666666668}\n",
      "dev score\n",
      "{'f1': 0.70315581854043396, 'recall': 0.76914778856526433, 'precision': 0.64759309718437785, 'accuracy': 0.69899999999999995}\n",
      "[epoch 4] Starting epoch 4\n",
      "Training: total loss: 35.290\n",
      "[epoch 4] Completed in 0:01:46\n",
      "train score\n",
      "{'f1': 0.94972607154366739, 'recall': 0.99966078697421978, 'precision': 0.90454266421117246, 'accuracy': 0.94799999999999995}\n",
      "dev score\n",
      "{'f1': 0.70155355682747345, 'recall': 0.92556634304207119, 'precision': 0.56484529295589203, 'accuracy': 0.63500000000000001}\n",
      "[epoch 5] Starting epoch 5\n",
      "Training: total loss: 30.596\n",
      "[epoch 5] Completed in 0:01:47\n",
      "train score\n",
      "{'f1': 0.99409482031381802, 'recall': 0.99932157394843957, 'precision': 0.98892245720040284, 'accuracy': 0.99416666666666664}\n",
      "dev score\n",
      "{'f1': 0.72003745318352064, 'recall': 0.82955771305285864, 'precision': 0.63606286186931349, 'accuracy': 0.70099999999999996}\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "max_length = 500\n",
    "num_classes = 1\n",
    "vocab_size = len(vocab.word_to_id)\n",
    "embedding_size = 200\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 128\n",
    "keep_prob = 0.8\n",
    "l2_reg_lambda = 0.5\n",
    "\n",
    "trained_filename = 'tf_saved/final_project_rnn_classifier_v2_3'\n",
    "\n",
    "model_params = dict(sequence_length=max_length, num_classes=num_classes, vocab_size=vocab_size,\n",
    "      embedding_size=embedding_size, filter_sizes=filter_sizes, num_filters=num_filters, \n",
    "      learning_rate=learning_rate, l2_reg_lambda=l2_reg_lambda)\n",
    "\n",
    "runTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score\n",
      "{'f1': 0.72125114995400186, 'recall': 0.8349307774227902, 'precision': 0.6348178137651822, 'accuracy': 0.69699999999999995}\n"
     ]
    }
   ],
   "source": [
    "# get score on test set\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "max_length = 500\n",
    "num_classes = 1\n",
    "vocab_size = len(vocab.word_to_id)\n",
    "embedding_size = 200\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 128\n",
    "keep_prob = 0.8\n",
    "l2_reg_lambda = 0.5\n",
    "\n",
    "trained_filename = 'tf_saved/final_project_rnn_classifier_v2_2'\n",
    "\n",
    "model_params = dict(sequence_length=max_length, num_classes=num_classes, vocab_size=vocab_size,\n",
    "      embedding_size=embedding_size, filter_sizes=filter_sizes, num_filters=num_filters, \n",
    "      learning_rate=learning_rate, l2_reg_lambda=l2_reg_lambda)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    with tf.variable_scope(\"model\", reuse=None):\n",
    "        lm = LanguageModel(**model_params)\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        saver = tf.train.Saver()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, trained_filename)\n",
    "    \n",
    "    print(\"test score\")\n",
    "    getScore(session, test_data, lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
