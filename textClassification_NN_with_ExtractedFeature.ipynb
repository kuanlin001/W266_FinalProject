{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load existing data\n",
    "with open('train_data_vec.p', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('dev_data_vec.p', 'rb') as f:\n",
    "    dev_data = pickle.load(f)\n",
    "with open('test_data_vec.p', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]['dataVector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchGenerator(dataset, batch_size, success_ratio=0.8):\n",
    "    for i in xrange(0, len(dataset), batch_size):\n",
    "        batch_data = dataset[i:i+batch_size]\n",
    "        x = []\n",
    "        y = []\n",
    "        raw = []\n",
    "        for data in batch_data:\n",
    "            x.append(data['dataVector'])\n",
    "            helpful_ratio = data[\"helpful\"][0]*1.0/data[\"helpful\"][1]\n",
    "            raw.append(data[\"helpful\"])\n",
    "            if helpful_ratio > success_ratio:\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "        yield (x, y, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextModel(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.learning_rate_ = tf.constant(0.01, name=\"learning_rate\")\n",
    "        \n",
    "        self.hidden1_size = 300\n",
    "        self.hidden2_size = 200\n",
    "        self.input_size = 200\n",
    "        \n",
    "        self.input_w_ = tf.placeholder(tf.float32, [None, None], name=\"w\")\n",
    "        self.target_y_ = tf.placeholder(tf.float32, [None], name=\"y\")\n",
    "        \n",
    "        with tf.variable_scope(\"hidden1\"):\n",
    "            self.w1 = tf.get_variable(\"w1\", shape=[self.input_size, self.hidden1_size], dtype=tf.float32,\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.b1 = tf.get_variable(\"b1\", dtype=tf.float32, \n",
    "                         initializer=tf.zeros_initializer([self.hidden1_size]))\n",
    "            self.h1 = tf.tanh(tf.matmul(self.input_w_, self.w1) + self.b1, name=\"h1\")\n",
    "            \n",
    "        with tf.variable_scope(\"hidden2\"):\n",
    "            self.w2 = tf.get_variable(\"w2\", shape=[self.hidden1_size, self.hidden2_size], dtype=tf.float32,\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.b2 = tf.get_variable(\"b2\", dtype=tf.float32, \n",
    "                         initializer=tf.zeros_initializer([self.hidden2_size]))\n",
    "            self.h2 = tf.tanh(tf.matmul(self.h1, self.w2) + self.b2, name=\"h2\")\n",
    "            \n",
    "        with tf.variable_scope(\"output_layer\"):\n",
    "            self.w_out = tf.get_variable(\"W_out\", shape=[self.hidden2_size, 1], dtype=tf.float32, \n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.b_out = tf.get_variable(\"b_out\", dtype=tf.float32, \n",
    "                           initializer=tf.zeros_initializer([1]))\n",
    "            self.logits_ = tf.add(tf.matmul(self.h2, self.w_out), self.b_out, name=\"logits\")\n",
    "            \n",
    "        with tf.name_scope(\"loss_function\"):\n",
    "            self.point_loss_ = tf.nn.sigmoid_cross_entropy_with_logits(tf.squeeze(self.logits_), self.target_y_)\n",
    "            self.loss_ = tf.reduce_mean(self.point_loss_)\n",
    "            \n",
    "        with tf.name_scope(\"train_ops\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(self.learning_rate_)\n",
    "            self.train_step_ = optimizer.minimize(self.loss_)\n",
    "            \n",
    "        with tf.name_scope(\"Prediction\"):\n",
    "            self.pred_proba_ = tf.sigmoid(self.logits_, name=\"pred_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "def score_batch(pred_probs, targets):\n",
    "    pred = [1 if p>0.5 else 0 for p in pred_probs]\n",
    "    accuracy = metrics.accuracy_score(targets, pred)\n",
    "    precision = metrics.precision_score(targets, pred)\n",
    "    recall = metrics.recall_score(targets, pred)\n",
    "    f1 = metrics.f1_score(targets, pred)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set baseline\n",
      "batch #0\n",
      "{'f1': 0.64309725281094243, 'recall': 0.94097693351424694, 'precision': 0.48846627927452019, 'accuracy': 0.48683333333333334}\n",
      "dev set baseline\n",
      "batch #0\n",
      "{'f1': 0.43810610382201942, 'recall': 0.41423948220064727, 'precision': 0.46489104116222763, 'accuracy': 0.50749999999999995}\n",
      "test set baseline\n",
      "batch #0\n",
      "{'f1': 0.63852961198093949, 'recall': 0.99893503727369537, 'precision': 0.46923461730865434, 'accuracy': 0.46899999999999997}\n"
     ]
    }
   ],
   "source": [
    "# baseline score - no training\n",
    "def baselineScore(dataset):\n",
    "    # test 2 batches on the first 10 training set\n",
    "    bi = batchGenerator(dataset, len(dataset), success_ratio=0.8)\n",
    "    \n",
    "    with tf.Graph().as_default(), tf.Session() as session:\n",
    "        with tf.variable_scope(\"model\", reuse=None):\n",
    "            lm = TextModel()\n",
    "        \n",
    "        session.run(tf.initialize_all_variables())\n",
    "        \n",
    "        for i,(w,y, raw) in enumerate(bi):\n",
    "            print(\"batch #%s\"%i)\n",
    "            feed_dict = { lm.input_w_:w}\n",
    "            pred_prob = session.run(lm.pred_proba_, feed_dict)\n",
    "            #print(pred_prob)\n",
    "            #print(y)\n",
    "            #print(raw)\n",
    "            print(score_batch(pred_prob, y))\n",
    "print(\"train set baseline\")\n",
    "baselineScore(train_data)\n",
    "print(\"dev set baseline\")\n",
    "baselineScore(dev_data)\n",
    "print(\"test set baseline\")\n",
    "baselineScore(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[epoch 20] Starting epoch 20\n",
      "Training: total loss: 831.909\n",
      "[epoch 20] Completed in 0:00:01\n",
      "train score\n",
      "{'f1': 0.58932446116013315, 'recall': 0.69097693351424694, 'precision': 0.51374527112232027, 'accuracy': 0.52683333333333338}\n",
      "dev score\n",
      "{'f1': 0.57015590200445432, 'recall': 0.6903991370010788, 'precision': 0.48558421851289835, 'accuracy': 0.51749999999999996}\n",
      "[epoch 40] Starting epoch 40\n",
      "Training: total loss: 830.038\n",
      "[epoch 40] Completed in 0:00:01\n",
      "train score\n",
      "{'f1': 0.58044444444444432, 'recall': 0.66451831750339208, 'precision': 0.51525512887953706, 'accuracy': 0.52800000000000002}\n",
      "dev score\n",
      "{'f1': 0.55882352941176472, 'recall': 0.65587918015102487, 'precision': 0.48678943154523618, 'accuracy': 0.52000000000000002}\n",
      "[epoch 60] Starting epoch 60\n",
      "Training: total loss: 828.756\n",
      "[epoch 60] Completed in 0:00:01\n",
      "train score\n",
      "{'f1': 0.55997494519260882, 'recall': 0.60651289009497966, 'precision': 0.52006980802792324, 'accuracy': 0.53166666666666662}\n",
      "dev score\n",
      "{'f1': 0.53797158255756983, 'recall': 0.59223300970873782, 'precision': 0.49281867145421904, 'accuracy': 0.52849999999999997}\n",
      "[epoch 80] Starting epoch 80\n",
      "Training: total loss: 827.781\n",
      "[epoch 80] Completed in 0:00:01\n",
      "train score\n",
      "{'f1': 0.57028112449799195, 'recall': 0.62618724559023065, 'precision': 0.52353942144072607, 'accuracy': 0.53633333333333333}\n",
      "dev score\n",
      "{'f1': 0.53857211308097752, 'recall': 0.60625674217907233, 'precision': 0.48448275862068968, 'accuracy': 0.51849999999999996}\n",
      "[epoch 100] Starting epoch 100\n",
      "Training: total loss: 827.039\n",
      "[epoch 100] Completed in 0:00:01\n",
      "train score\n",
      "{'f1': 0.56908809891808332, 'recall': 0.62449118046132968, 'precision': 0.52271436683702444, 'accuracy': 0.53533333333333333}\n",
      "dev score\n",
      "{'f1': 0.54146806482364152, 'recall': 0.61272923408845736, 'precision': 0.48505550811272419, 'accuracy': 0.51900000000000002}\n",
      "train score\n",
      "{'f1': 0.56908809891808332, 'recall': 0.62449118046132968, 'precision': 0.52271436683702444, 'accuracy': 0.53533333333333333}\n",
      "dev score\n",
      "{'f1': 0.54146806482364152, 'recall': 0.61272923408845736, 'precision': 0.48505550811272419, 'accuracy': 0.51900000000000002}\n"
     ]
    }
   ],
   "source": [
    "# run training\n",
    "trained_filename = 'tf_saved/nn_text_classifier'\n",
    "batch_size = 5\n",
    "learning_rate = 0.1\n",
    "num_epochs = 100\n",
    "import time\n",
    "import utils; reload(utils)\n",
    "\n",
    "def runTraining(print_interval=20):\n",
    "    with tf.Graph().as_default(), tf.Session() as session:\n",
    "        tf.set_random_seed(42)\n",
    "        with tf.variable_scope(\"model\", reuse=None):\n",
    "            lm = TextModel()\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        for epoch in xrange(1,num_epochs+1):\n",
    "            t0_epoch = time.time()\n",
    "            bi = batchGenerator(train_data, batch_size, success_ratio=0.8)\n",
    "            if epoch == 1 or epoch%print_interval == 0:\n",
    "                print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "            cost = 0.0\n",
    "            for (w, y, _) in bi:\n",
    "                feed_dict = {\n",
    "                    lm.learning_rate_: learning_rate,\n",
    "                    lm.input_w_: w,\n",
    "                    lm.target_y_: y\n",
    "                }\n",
    "                _, loss_val = session.run([lm.train_step_, lm.loss_], feed_dict)\n",
    "                cost += loss_val\n",
    "            \n",
    "            if epoch%print_interval == 0:\n",
    "                print \"%s: total loss: %.03f\" % (\"Training\", cost)\n",
    "                print \"[epoch %d] Completed in %s\" % (epoch, utils.pretty_timedelta(since=t0_epoch))\n",
    "\n",
    "                print(\"train score\")\n",
    "                bi = batchGenerator(train_data, len(train_data), 0.8)\n",
    "                for (w,y, _) in bi:\n",
    "                    feed_dict = { lm.input_w_:w}\n",
    "                    pred_prob = session.run(lm.pred_proba_, feed_dict)\n",
    "                    print(score_batch(pred_prob, y))\n",
    "\n",
    "                print(\"dev score\")\n",
    "                bi = batchGenerator(dev_data, len(dev_data), 0.8)\n",
    "                for (w,y, _) in bi:\n",
    "                    feed_dict = { lm.input_w_:w}\n",
    "                    pred_prob = session.run(lm.pred_proba_, feed_dict)\n",
    "                    print(score_batch(pred_prob, y))\n",
    "                \n",
    "        print(\"train score\")\n",
    "        bi = batchGenerator(train_data, len(train_data), 0.8)\n",
    "        for (w,y, _) in bi:\n",
    "            feed_dict = { lm.input_w_:w}\n",
    "            pred_prob = session.run(lm.pred_proba_, feed_dict)\n",
    "            print(score_batch(pred_prob, y))\n",
    "\n",
    "        print(\"dev score\")\n",
    "        bi = batchGenerator(dev_data, len(dev_data), 0.8)\n",
    "        for (w,y, _) in bi:\n",
    "            feed_dict = { lm.input_w_:w}\n",
    "            pred_prob = session.run(lm.pred_proba_, feed_dict)\n",
    "            print(score_batch(pred_prob, y))\n",
    "        # Save final model\n",
    "        saver.save(session, trained_filename)\n",
    "runTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score\n",
      "{'f1': 0.53402646502835538, 'recall': 0.6017039403620873, 'precision': 0.48003398470688191, 'accuracy': 0.50700000000000001}\n"
     ]
    }
   ],
   "source": [
    "# test score\n",
    "trained_filename = 'tf_saved/nn_text_classifier'\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    with tf.variable_scope(\"model\", reuse=None):\n",
    "        lm = TextModel()\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        saver = tf.train.Saver()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, trained_filename)\n",
    "    \n",
    "    print(\"test score\")\n",
    "    bi = batchGenerator(test_data, len(test_data), 0.8)\n",
    "    for (w,y, _) in bi:\n",
    "        feed_dict = { lm.input_w_:w}\n",
    "        pred_prob = session.run(lm.pred_proba_, feed_dict)\n",
    "        print(score_batch(pred_prob, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
